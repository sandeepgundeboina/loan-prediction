import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits import mplot3d
import matplotlib.colors
my_cmap = matplotlib.colors.LinearSegmentedColormap.from_list("", ["red","yellow","green"])
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,mean_squared_error
from tqdm import tqdm_notebook
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import log_loss
from sklearn.preprocessing import StandardScaler,MinMaxScaler
from PIL import Image, ImageFilter
from tqdm import tqdm_notebook
from sklearn.metrics import accuracy_score, mean_squared_error, log_loss, confusion_matrix
from sklearn import metrics
from sklearn.preprocessing import OneHotEncoder
from sklearn.datasets import make_blobs
import seaborn as sns
loan=pd.read_csv('train_loan.csv')
loan
def missing_values_table(df):
        # Total missing values
        mis_val = df.isnull().sum()
        
        # Percentage of missing values
        mis_val_percent = 100 * df.isnull().sum() / len(df)
        
        # Make a table with the results
        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)
        
        # Rename the columns
        mis_val_table_ren_columns = mis_val_table.rename(
        columns = {0 : 'Missing Values', 1 : '% of Total Values'})
        
        # Sort the table by percentage of missing descending
        mis_val_table_ren_columns = mis_val_table_ren_columns[
            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(
        '% of Total Values', ascending=False).round(1)
        
        # Print some summary information
        print ("Your selected dataframe has " + str(df.shape[1]) + " columns.\n"      
            "There are " + str(mis_val_table_ren_columns.shape[0]) +
              " columns that have missing values.")
        
        # Return the dataframe with missing information
        return mis_val_table_ren_columns
missing_values_table(loan).head(50)
loan['Credit_History'].fillna(1,inplace=True)
loan.fillna(loan.mean(), inplace=True)
loan = loan.apply(lambda x: x.fillna(x.value_counts().index[0]))
loan['Property_Area']=loan['Property_Area'].replace({'Semiurban' : 0, 'Urban' : 1,'Rural' : 2})
loan['Married']=loan['Married'].replace({'Yes' : 1, 'No' : 0})
loan['Gender']=loan['Gender'].replace({'Female' : 0, 'Male' : 1})
loan['Dependents']=loan['Dependents'].replace({'0' : 0, '1' : 1,'2' : 2,'3+':3})
loan['Education']=loan['Education'].replace({'Not Graduate' : 0, 'Graduate' : 1})
loan['Loan_Status']=loan['Loan_Status'].replace({'N' : 0, 'Y' : 1})
#data Visulisation
sns.set()
sns.countplot(x='Loan_Status',data=loan)
plt.show()
numerical_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']
categorical_columns = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area','Credit_History','Loan_Amount_Term']
fig,axes = plt.subplots(4,2,figsize=(12,15))
for idx,cat_col in enumerate(categorical_columns):
    row,col = idx//2,idx%2
    sns.countplot(x=cat_col,data=loan,hue='Loan_Status',ax=axes[row,col])
plt.subplots_adjust(hspace=1)
ig,axes = plt.subplots(1,3,figsize=(17,5))
for idx,cat_col in enumerate(numerical_columns):
    sns.boxplot(y=cat_col,data=loan,x='Loan_Status',ax=axes[idx])
plt.subplots_adjust(hspace=1)
#train_test_splitting
X=loan_df.drop(['Loan_Status'],axis=1)
Y=loan_df['Loan_Status']
X
from 
sand=pd.read_csv('test_loan.csv')
missing_values_table(sand).head(50)
sand['Credit_History'].fillna(1,inplace=True)
sand.fillna(sand.mean(),inplace=True)
sand = sand.apply(lambda x: x.fillna(x.value_counts().index[0]))
sand['Gender']=sand['Gender'].replace({'Male':1,'Female':0})
sand['Education']=sand['Education'].replace({'Graduate':1,'Not Graduate':0})
sand['Dependents']=sand['Dependents'].replace({'1':1,'2':2,'0':0,'3+':3})
sand['Self_Employed']=sand['Self_Employed'].replace({'Yes':1,'No':0})
sand['Married']=sand['Married'].replace({'Yes':1,'No':0})
sand['Property_Area']=sand['Property_Area'].replace({'Semiurban' : 0, 'Urban' : 1,'Rural' : 2})
sand=sand.drop('Loan_ID',axis=1)
#applying classification
from sklearn.ensemble import RandomForestClassifier
model=RandomForestClassifier(n_estimators=1500,n_jobs=1,max_leaf_nodes=4,min_weight_fraction_leaf=0.2)
model.fit(X,Y)
model.predict
y_predicted=model.predict(sand)
